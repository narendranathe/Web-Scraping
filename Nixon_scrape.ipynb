{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/narendranathe/Web-Scraping/blob/main/Nixon_scrape.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sure, here is the step-by-step Python code for scraping reviews from the TripAdvisor page:"
      ],
      "metadata": {
        "id": "GN2XzqjavxUx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from selenium import webdriver\n",
        "from selenium.webdriver.chrome.options import Options\n",
        "from bs4 import BeautifulSoup\n",
        "import re\n",
        "import time\n",
        "\n",
        "chrome_options = Options()\n",
        "chrome_options.add_argument('--headless')\n",
        "chrome_options.add_argument('--no-sandbox')\n",
        "chrome_options.add_argument('--disable-dev-shm-usage')\n",
        "d = webdriver.Chrome(options=chrome_options)\n",
        "\n",
        "i = 0\n",
        "while (True):\n",
        "  url = \"https://www.tripadvisor.in/Attraction_Review-g33298-d102419-Reviews-or\" + str(i) + \"-Richard_Nixon_Presidential_Library_and_Museum-Yorba_Linda_California.html\"\n",
        "  i = i + 10\n",
        "  d.get(url)\n",
        "  soup = BeautifulSoup(d.page_source, 'html.parser')\n",
        "  reviews = soup.find('div', class_ ='LbPSX').find_all('div', attrs={'data-automation': 'tab'})\n",
        "  if (len(reviews) < 2):\n",
        "    break\n",
        "  for review in reviews:\n",
        "    reviewerId = review.find('span', class_ = 'biGQs _P fiohW fOtGX')\n",
        "    if reviewerId:\n",
        "      print(\"name :\" + reviewerId.text)\n",
        "    reviewer_details = review.find('div', class_ = 'JINyA')\n",
        "    if (reviewer_details):\n",
        "      reviewer_address = reviewer_details.find('span')\n",
        "      if reviewer_address and not reviewer_address.has_attr('class'):\n",
        "        print(\"add :\" + reviewer_address.text)\n",
        "      contributions = reviewer_details.find('span', class_ = 'IugUm')\n",
        "      if contributions:\n",
        "        print(\"contrib :\" + contributions.text)\n",
        "    likes = review.find('span', class_ = 'kLqdM')\n",
        "    print(\"likes: \" + likes.text if likes else \"Not found\")\n",
        "    ratings = review.find('svg', class_='UctUV d H0')\n",
        "    print(ratings['aria-label'] if ratings and 'aria-label' in ratings.attrs else \"Not found\")\n",
        "    headline = review.find('div', class_ = 'biGQs _P fiohW qWPrE ncFvv fOtGX')\n",
        "    print(\"headline: \" + headline.text if headline else \"Not found\")\n",
        "    content = review.find('div', class_ = 'biGQs _P pZUbB KxBGd')\n",
        "    print(\"content: \" + content.text if content else \"Not found\")\n",
        "\n",
        " # Store the data in a list of lists\n",
        "    review_data = [reviewer_Id, reviewer_address, contributions, likes_text, ratings_text, headline_text, content_text]\n",
        "    all_reviews.append(review_data)\n",
        "d.quit()\n",
        "\n",
        "# Save data to a text file\n",
        "with open(\"tripadvisor_reviews.txt\", \"w\", encoding=\"utf-8\") as txt_file:\n",
        "    for review_data in all_reviews:\n",
        "        txt_file.write(\"\\t\".join(map(str, review_data)) + \"\\n\")\n",
        "\n",
        "# Save data to an Excel file\n",
        "wb = openpyxl.Workbook()\n",
        "ws = wb.active\n",
        "\n",
        "# Add headers\n",
        "headers = [\"Name\", \"Address\", \"Contributions\", \"Likes\", \"Ratings\", \"Headline\", \"Content\"]\n",
        "ws.append(headers)\n",
        "\n",
        "# Add data to the Excel worksheet\n",
        "for review_data in all_reviews:\n",
        "    ws.append(review_data)\n",
        "\n",
        "# Save the Excel workbook\n",
        "wb.save(\"tripadvisor_reviews.xlsx\")\n",
        "\n",
        "# Close the workbook\n",
        "wb.close()\n",
        "\n",
        "\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "name :motorcar1\n",
            "add :Dublin, Ireland\n",
            "contrib :8,111 contributions\n",
            "likes: 0\n",
            "5.0 of 5 bubbles\n",
            "headline: Nixon Museum and library\n",
            "content: Visited here during US trip 2022. A pleasant place to visit and get a real feel about Richard Nixon and the Vietnam war. You get the positives and negatives of the Nixon presidency. Really interesting and a beautiful setting.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-839905ae2e21>\u001b[0m in \u001b[0;36m<cell line: 14>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m  \u001b[0;31m# Store the data in a list of lists\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m     \u001b[0mreview_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mreviewer_Id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreviewer_address\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontributions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlikes_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mratings_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheadline_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontent_text\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m     \u001b[0mall_reviews\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreview_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'reviewer_Id' is not defined"
          ]
        }
      ],
      "execution_count": null,
      "metadata": {
        "id": "9bGrwgurvxU0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        },
        "outputId": "d58878b4-c5cf-4ec5-f03c-a34f7e4193e1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from selenium import webdriver\n",
        "from selenium.webdriver.chrome.options import Options\n",
        "from bs4 import BeautifulSoup\n",
        "import re\n",
        "import time\n",
        "import openpyxl\n",
        "\n",
        "chrome_options = Options()\n",
        "chrome_options.add_argument('--headless')\n",
        "chrome_options.add_argument('--no-sandbox')\n",
        "chrome_options.add_argument('--disable-dev-shm-usage')\n",
        "d = webdriver.Chrome(options=chrome_options)\n",
        "\n",
        "i = 0\n",
        "all_reviews = []\n",
        "\n",
        "while True:\n",
        "    url = \"https://www.tripadvisor.in/Attraction_Review-g33298-d102419-Reviews-or\" + str(i) + \"-Richard_Nixon_Presidential_Library_and_Museum-Yorba_Linda_California.html\"\n",
        "    i = i + 10\n",
        "    d.get(url)\n",
        "    soup = BeautifulSoup(d.page_source, 'html.parser')\n",
        "    reviews = soup.find('div', class_='LbPSX').find_all('div', attrs={'data-automation': 'tab'})\n",
        "    if len(reviews) < 2:\n",
        "        break\n",
        "    for review in reviews:\n",
        "        reviewer_id = review.find('span', class_='biGQs _P fiohW fOtGX')\n",
        "        reviewer_id_text = reviewer_id.text if reviewer_id else \"Not found\"\n",
        "\n",
        "        reviewer_details = review.find('div', class_='JINyA')\n",
        "        reviewer_address = \"\"\n",
        "        contributions = \"\"\n",
        "        if reviewer_details:\n",
        "            reviewer_address_span = reviewer_details.find('span')\n",
        "            if reviewer_address_span and not reviewer_address_span.has_attr('class'):\n",
        "                reviewer_address = reviewer_address_span.text\n",
        "            contributions_span = reviewer_details.find('span', class_='IugUm')\n",
        "            if contributions_span:\n",
        "                contributions = contributions_span.text\n",
        "\n",
        "        likes = review.find('span', class_='kLqdM')\n",
        "        likes_text = likes.text if likes else \"Not found\"\n",
        "\n",
        "        ratings = review.find('svg', class_='UctUV d H0')\n",
        "        ratings_text = ratings['aria-label'] if ratings and 'aria-label' in ratings.attrs else \"Not found\"\n",
        "\n",
        "        headline = review.find('div', class_='biGQs _P fiohW qWPrE ncFvv fOtGX')\n",
        "        headline_text = headline.text if headline else \"Not found\"\n",
        "\n",
        "        content = review.find('div', class_='biGQs _P pZUbB KxBGd')\n",
        "        content_text = content.text if content else \"Not found\"\n",
        "\n",
        "        # Store the data in a list of lists\n",
        "        review_data = [reviewer_id_text, reviewer_address, contributions, likes_text, ratings_text, headline_text, content_text]\n",
        "        all_reviews.append(review_data)\n",
        "\n",
        "d.quit()\n",
        "\n",
        "# Save data to a text file\n",
        "with open(\"tripadvisor_reviews.txt\", \"w\", encoding=\"utf-8\") as txt_file:\n",
        "    for review_data in all_reviews:\n",
        "        txt_file.write(\"\\t\".join(map(str, review_data)) + \"\\n\")\n",
        "\n",
        "# Save data to an Excel file\n",
        "wb = openpyxl.Workbook()\n",
        "ws = wb.active\n",
        "\n",
        "# Add headers\n",
        "headers = [\"Name\", \"Address\", \"Contributions\", \"Likes\", \"Ratings\", \"Headline\", \"Content\"]\n",
        "ws.append(headers)\n",
        "\n",
        "# Add data to the Excel worksheet\n",
        "for review_data in all_reviews:\n",
        "    ws.append(review_data)\n",
        "\n",
        "# Save the Excel workbook\n",
        "wb.save(\"tripadvisor_reviews.xlsx\")\n",
        "\n",
        "# Close the workbook\n",
        "wb.close()\n"
      ],
      "metadata": {
        "id": "cgOSTsLfpcKQ"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "# Download the Excel file\n",
        "files.download('tripadvisor_reviews.xlsx')\n",
        "\n",
        "# Download the text file\n",
        "files.download('tripadvisor_reviews.txt')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "hMpqN99Y9qv8",
        "outputId": "4c64db23-128b-4375-cce7-345db0328841"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_5e52f44d-c5b5-4c52-a8cd-9042c2a30350\", \"tripadvisor_reviews.xlsx\", 263113)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_f176fb5c-ef64-4715-b8ae-efcf1d56a1e0\", \"tripadvisor_reviews.txt\", 616376)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install selenium"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xyO5OE7_nKr6",
        "outputId": "4191f73d-0831-4189-b687-beaff25cc0b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting selenium\n",
            "  Downloading selenium-4.12.0-py3-none-any.whl (9.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.4/9.4 MB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: urllib3[socks]<3,>=1.26 in /usr/local/lib/python3.10/dist-packages (from selenium) (2.0.4)\n",
            "Collecting trio~=0.17 (from selenium)\n",
            "  Downloading trio-0.22.2-py3-none-any.whl (400 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m400.2/400.2 kB\u001b[0m \u001b[31m34.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting trio-websocket~=0.9 (from selenium)\n",
            "  Downloading trio_websocket-0.10.3-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: certifi>=2021.10.8 in /usr/local/lib/python3.10/dist-packages (from selenium) (2023.7.22)\n",
            "Requirement already satisfied: attrs>=20.1.0 in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (23.1.0)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (2.4.0)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (3.4)\n",
            "Collecting outcome (from trio~=0.17->selenium)\n",
            "  Downloading outcome-1.2.0-py2.py3-none-any.whl (9.7 kB)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.0rc9 in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (1.1.3)\n",
            "Collecting wsproto>=0.14 (from trio-websocket~=0.9->selenium)\n",
            "  Downloading wsproto-1.2.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
            "Collecting h11<1,>=0.9.0 (from wsproto>=0.14->trio-websocket~=0.9->selenium)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: outcome, h11, wsproto, trio, trio-websocket, selenium\n",
            "Successfully installed h11-0.14.0 outcome-1.2.0 selenium-4.12.0 trio-0.22.2 trio-websocket-0.10.3 wsproto-1.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code will first get the HTML content of the TripAdvisor page. Then, it will parse the HTML content using BeautifulSoup. Next, it will find all the review elements on the page. Finally, it will loop through the review elements and extract the review text. The reviews will then be printed to the console.\n",
        "\n",
        "Here is an explanation of the code:\n",
        "\n",
        "* The `requests` library is used to get the HTML content of the TripAdvisor page.\n",
        "* The `BeautifulSoup` library is used to parse the HTML content.\n",
        "* The `find_all()` method of the `BeautifulSoup` object is used to find all the review elements on the page.\n",
        "* The `text()` method of the `review_element` object is used to extract the review text.\n",
        "* The `append()` method of the `reviews` list is used to add the review text to the list.\n",
        "* The `print()` function is used to print the reviews to the console.\n",
        "\n",
        "I hope this helps!"
      ],
      "metadata": {
        "id": "Nwi-yqSMvxU1"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}